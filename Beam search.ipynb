{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf52f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1b2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_width = 10\n",
    "batch_size = 2\n",
    "num_nodes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fee8d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "y = torch.randn(batch_size, num_nodes, num_nodes, 2).type(torch.float)\n",
    "y_pred = torch.nn.functional.softmax(y, dim=3)\n",
    "y_pred = y_pred[:, :, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee0446db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.zeros(batch_size, num_nodes, num_nodes).type(torch.float)\n",
    "\n",
    "for i in range(num_nodes):\n",
    "    j = (i + 1) % num_nodes\n",
    "    k = (i + 2) % num_nodes\n",
    "    y_pred[0][i][i] = 0\n",
    "    y_pred[0][i][j] = 0.8\n",
    "    y_pred[0][i][k] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "718f32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Beamsearch:\n",
    "    \"\"\"\n",
    "    Beam search procedure class.\n",
    "\n",
    "    References:\n",
    "        [1]: https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/translate/beam.py\n",
    "        [2]: https://github.com/alexnowakvila/QAP_pt/blob/master/src/tsp/beam_search.py\n",
    "        [3]: https://github.com/chaitjo/graph-convnet-tsp/blob/master/utils/beamsearch.py\n",
    "    \"\"\"\n",
    "    def __init__(self, beam_width, trans_probs, num_vehicles=1, random_start=False):\n",
    "        # all transition probabilities\n",
    "        self.trans_probs = trans_probs\n",
    "        self.batch_size = trans_probs.size(0)\n",
    "        self.num_nodes = trans_probs.size(1)\n",
    "        self.num_vehicles = num_vehicles\n",
    "        \n",
    "        assert len(trans_probs.shape) == 3, \"transition probabilities need to be 3-dimensional\"\n",
    "        assert trans_probs.size(1) == trans_probs.size(2), \"transition probabilities are not square\"\n",
    "        \n",
    "        # Beamsearch parameters\n",
    "        self.beam_width = beam_width\n",
    "\n",
    "        # TODO: Move tensors to GPU device for faster computation\n",
    "        # tensor data types and device\n",
    "        self.device = None\n",
    "        self.float = torch.float32\n",
    "        self.long = torch.int64\n",
    "        \n",
    "        if random_start == True:\n",
    "            # starting at random nodes\n",
    "            start_nodes = torch.randint(0, self.num_nodes, (self.batch_size, self.beam_width))\n",
    "        else:\n",
    "            # starting at node zero\n",
    "            start_nodes = torch.zeros(self.batch_size, self.beam_width)\n",
    "        \n",
    "        self.start_nodes = start_nodes.type(self.long)\n",
    "        self.depot_visits_counter = torch.zeros(self.batch_size, self.beam_width)\n",
    "        \n",
    "        # TODO: could also mask self-connections\n",
    "        # mask for removing visited nodes etc.\n",
    "        self.mask = torch.ones(self.batch_size, self.beam_width, self.num_nodes).type(self.float)\n",
    "        \n",
    "        # start by masking the starting nodes\n",
    "        self.update_mask(self.start_nodes)\n",
    "        \n",
    "        # transition probability scores up-until current timestep\n",
    "        self.scores = torch.zeros(self.batch_size, self.beam_width).type(self.float)\n",
    "        \n",
    "        # pointers to parents for each timestep\n",
    "        self.parent_pointer  = []\n",
    "        \n",
    "        # nodes at each timestep\n",
    "        self.next_nodes = [self.start_nodes]\n",
    "\n",
    "    def get_current_nodes(self):\n",
    "        \"\"\"\n",
    "        Get the nodes to expand at the current timestep\n",
    "        \"\"\"\n",
    "        current_nodes = self.next_nodes[-1]\n",
    "        current_nodes = current_nodes.unsqueeze(2).expand(self.batch_size,\n",
    "                                                          self.beam_width, \n",
    "                                                          self.num_nodes)\n",
    "        return current_nodes\n",
    "    \n",
    "    @property\n",
    "    def num_iterations(self):\n",
    "        # -1 for num_nodes because we already start at depot\n",
    "        # -1 to offset num_vehicles\n",
    "        return self.num_nodes - 1 + self.num_vehicles - 1\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Start beam search\n",
    "        \"\"\"\n",
    "        \n",
    "        for step in range(self.num_iterations):\n",
    "            self.step()\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Transition to the next timestep of the beam search\n",
    "        \"\"\"\n",
    "        current_nodes = self.get_current_nodes()\n",
    "        trans_probs = self.trans_probs.gather(1, current_nodes)\n",
    "        \n",
    "        if len(self.parent_pointer) == 0:\n",
    "            # first transition, only use the starting nodes\n",
    "            beam_prob = trans_probs\n",
    "            beam_prob[:, 1:] = torch.zeros_like(beam_prob[:, 1:])\n",
    "        else:\n",
    "            # multiply the previous scores (probabilities) with the current ones\n",
    "            expanded_scores = self.scores.unsqueeze(2).expand_as(trans_probs) # b x beam_width x num_nodes\n",
    "            beam_prob = trans_probs * expanded_scores\n",
    "        \n",
    "        # mask out visited nodes\n",
    "        beam_prob = beam_prob * self.mask\n",
    "        \n",
    "        beam_prob = beam_prob.view(beam_prob.size(0), -1) # flatten to (b x beam_width * num_nodes)\n",
    "        \n",
    "        # get k=beam_width best scores and indices\n",
    "        best_scores, best_score_idxs = beam_prob.topk(self.beam_width,\n",
    "                                                      dim=1, largest=True, sorted=True)\n",
    "        \n",
    "        self.scores = best_scores\n",
    "        parent_index = torch.floor_divide(best_score_idxs, self.num_nodes).type(self.long)\n",
    "        \n",
    "        self.parent_pointer.append(parent_index)\n",
    "        \n",
    "        # next nodes\n",
    "        next_node = best_score_idxs - (parent_index * self.num_nodes) # convert flat indices back to original\n",
    "        self.next_nodes.append(next_node)\n",
    "        \n",
    "        # keep masked rows from parents (for next step)\n",
    "        parent_mask = parent_index.unsqueeze(2).expand_as(self.mask)  # (batch_size, beam_size, num_nodes)\n",
    "        self.mask = self.mask.gather(1, parent_mask)\n",
    "        \n",
    "        # keep depot counter from parent (for next step)\n",
    "        self.depot_visits_counter = self.depot_visits_counter.gather(1, parent_index)\n",
    "        \n",
    "        # mask next nodes (newly added nodes)\n",
    "        self.update_mask(next_node)\n",
    "\n",
    "    def update_mask(self, new_nodes):\n",
    "        \"\"\"\n",
    "        Sets indicies of new_nodes = 0 in the mask.\n",
    "        \n",
    "        Args:\n",
    "            new_nodes: (batch_size, beam_width) of new node indicies\n",
    "        \"\"\"\n",
    "        index = torch.arange(0, self.num_nodes, dtype=self.long).expand_as(self.mask)\n",
    "        new_nodes = new_nodes.unsqueeze(2).expand_as(self.mask)\n",
    "        \n",
    "        # set the mask = 0 at the new_node_idx positions\n",
    "        update_mask = torch.ne(index, new_nodes).type(self.float)\n",
    "        \n",
    "        # are we currently visiting the depot?\n",
    "        is_visiting_depot = torch.eq(update_mask[:, :, 0], 0)\n",
    "        not_visiting_depot = torch.logical_not(is_visiting_depot)\n",
    "\n",
    "        # increment depot visit counter where visited\n",
    "        self.depot_visits_counter += is_visiting_depot.type(self.float)\n",
    "        is_depot_available = torch.lt(self.depot_visits_counter, self.num_vehicles)\n",
    "        \n",
    "        # allow another depot visit (as floats)\n",
    "        allow_depot_visit = torch.logical_and(not_visiting_depot,\n",
    "                                              is_depot_available).type(self.float)\n",
    "        \n",
    "        self.mask = self.mask * update_mask\n",
    "        self.mask[:, :, 0] = allow_depot_visit\n",
    "\n",
    "    def get_beam(self, beam_idx):\n",
    "        \"\"\"\n",
    "        Construct the beam for the given index\n",
    "\n",
    "        Args:\n",
    "            beam_idx int: Index of the beam to construct (0 = best, ..., n = worst)\n",
    "        \"\"\"\n",
    "        # TODO: Fix assertion (with vehicles)\n",
    "        # assert self.num_nodes == len(self.parent_pointers) + 1\n",
    "        \n",
    "        prev_pointer = torch.ones(self.batch_size, 1).type(self.long) * beam_idx\n",
    "        last_node = self.next_nodes[-1].gather(1, prev_pointer)\n",
    "        \n",
    "        path = [last_node]\n",
    "        \n",
    "        for i in range(len(self.parent_pointer) - 1, -1, -1):\n",
    "            prev_pointer = self.parent_pointer[i].gather(1, prev_pointer)\n",
    "            last_node = self.next_nodes[i].gather(1, prev_pointer)\n",
    "            \n",
    "            path.append(last_node)\n",
    "        \n",
    "        path = list(reversed(path))\n",
    "        path = torch.cat(path, dim=-1)\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    def validate(self, beam, batch_idx=None, beam_idx=None):\n",
    "        bin_count = torch.bincount(beam)\n",
    "        \n",
    "        assert bin_count[0] <= self.num_vehicles, f\"Batch={batch_idx}, beam={beam_idx}: too many depot visits {bin_count[0]} > {self.num_vehicles}\\n{beam}\"\n",
    "        # want them seperate for sanity\n",
    "        assert torch.all(bin_count[1:] <= 1), f\"Batch={batch_idx}, beam={beam_idx}: too many node visits\\n{beam}\"\n",
    "        assert torch.all(bin_count[1:] > 0), f\"Batch={batch_idx}, beam={beam_idx}: not all node visited\\n{beam}\"\n",
    "    \n",
    "    def sanity_check(self):\n",
    "        for beam_idx in range(self.beam_width):\n",
    "            beams = self.get_beam(beam_idx)\n",
    "            \n",
    "            for batch_idx in range(beams.size(0)):\n",
    "                beam = beams[batch_idx]\n",
    "                \n",
    "                self.validate(beam, batch_idx=batch_idx, beam_idx=beam_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43eac4ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_vehicles = 3\n",
    "\n",
    "beamsearch = Beamsearch(beam_width, trans_probs=y_pred, num_vehicles=num_vehicles)\n",
    "beamsearch.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453c5fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 4, 2, 5, 1, 0, 3, 0],\n",
       "        [0, 3, 2, 0, 5, 0, 1, 4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_tours = beamsearch.get_beam(0)\n",
    "shortest_tours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baaf292d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Batch=0, beam=4: too many node visits\ntensor([0, 4, 1, 3, 2, 5, 0, 4])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbeamsearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 192\u001b[0m, in \u001b[0;36mBeamsearch.sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(beams\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)):\n\u001b[1;32m    190\u001b[0m     beam \u001b[38;5;241m=\u001b[39m beams[batch_idx]\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 182\u001b[0m, in \u001b[0;36mBeamsearch.validate\u001b[0;34m(self, beam, batch_idx, beam_idx)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m bin_count[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_vehicles, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, beam=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeam_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: too many depot visits \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbin_count[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_vehicles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mbeam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# want them seperate for sanity\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(bin_count[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, beam=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeam_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: too many node visits\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mbeam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(bin_count[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, beam=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeam_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: not all node visited\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mbeam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Batch=0, beam=4: too many node visits\ntensor([0, 4, 1, 3, 2, 5, 0, 4])"
     ]
    }
   ],
   "source": [
    "beamsearch.sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6814c2b4",
   "metadata": {},
   "source": [
    "The problem with the double visits is when the second to last node was the depot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "432fe124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[0, 4, 2, 5, 1, 0, 3, 0],\n",
      "        [0, 3, 2, 0, 5, 0, 1, 4]])\n",
      "\n",
      "1 tensor([[0, 4, 2, 1, 5, 0, 3, 0],\n",
      "        [0, 5, 0, 3, 2, 0, 1, 4]])\n",
      "\n",
      "2 tensor([[0, 4, 2, 3, 5, 0, 1, 0],\n",
      "        [0, 3, 2, 0, 1, 4, 5, 0]])\n",
      "\n",
      "3 tensor([[0, 4, 3, 2, 5, 0, 1, 0],\n",
      "        [0, 1, 3, 2, 0, 5, 4, 0]])\n",
      "\n",
      "4 tensor([[0, 4, 1, 3, 2, 5, 0, 4],\n",
      "        [0, 5, 3, 2, 0, 1, 4, 0]])\n",
      "\n",
      "5 tensor([[0, 4, 1, 3, 2, 5, 0, 5],\n",
      "        [0, 3, 2, 0, 5, 4, 0, 1]])\n",
      "\n",
      "6 tensor([[0, 4, 2, 1, 3, 5, 0, 0],\n",
      "        [0, 3, 2, 0, 5, 4, 1, 0]])\n",
      "\n",
      "7 tensor([[0, 4, 2, 1, 3, 5, 0, 1],\n",
      "        [0, 1, 3, 2, 0, 5, 0, 4]])\n",
      "\n",
      "8 tensor([[0, 4, 2, 1, 3, 5, 0, 2],\n",
      "        [0, 5, 0, 3, 2, 4, 0, 1]])\n",
      "\n",
      "9 tensor([[0, 4, 2, 1, 3, 5, 0, 3],\n",
      "        [0, 5, 0, 3, 2, 4, 1, 0]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for beam_idx in range(beamsearch.beam_width):\n",
    "    beams = beamsearch.get_beam(beam_idx)\n",
    "    print(beam_idx, beams)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03112d",
   "metadata": {},
   "source": [
    "## Tour distance\n",
    "\n",
    "The code below can serve as a good starting point for calculating the distance of the tour found so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b1064b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offset by one to calculate total travel distance\n",
    "idx = (torch.arange(0, shortest_tours.size(1)) + 1) % shortest_tours.size(1)\n",
    "idx = idx.expand_as(shortest_tours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6edf332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 2, 3, 1, 0],\n",
       "        [3, 2, 4, 1, 0],\n",
       "        [4, 3, 1, 2, 0]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_tours.gather(1, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
