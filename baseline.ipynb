{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline GNN model\n",
    "\n",
    "For the baseline model we will use a fully connected graph, and in the first iteration ignore the edge features (weights). This model should do better than a simple MLP at classifying the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from itertools import permutations\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTANCE_PATH = Path(\"data\")\n",
    "RESULTS_PATH = Path(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data\n",
    "\n",
    "Pre-processing the data so that it's in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INSTANCE_PATH / 'dataset.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.5       , 0.5       , 0.        ],\n",
       "        [0.06505159, 0.94888554, 2.        ],\n",
       "        [0.96563203, 0.80839735, 4.        ],\n",
       "        [0.30461377, 0.09767211, 8.        ],\n",
       "        [0.68423303, 0.44015249, 7.        ],\n",
       "        [0.12203823, 0.49517691, 9.        ],\n",
       "        [0.03438852, 0.9093204 , 8.        ],\n",
       "        [0.25877998, 0.66252228, 5.        ],\n",
       "        [0.31171108, 0.52006802, 2.        ],\n",
       "        [0.54671028, 0.18485446, 5.        ],\n",
       "        [0.96958463, 0.77513282, 8.        ]]),\n",
       " array([-1,  0,  1,  2,  1,  0,  0,  0,  2,  2,  1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = data[0]\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the graph is fully connected and the edge features (representing the distance between each neighbour) is ignored.\n",
    "\n",
    "It's not yet clear how the the demand capacities of the vehicles will be modeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(graph[0])\n",
    "y = torch.tensor(graph[1] + 1)\n",
    "edge_indices = torch.tensor(list(permutations(np.arange(x.size(0)), r=2)), dtype=torch.long).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 3]), torch.Size([11]), torch.Size([2, 110]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, edge_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(graph):\n",
    "    x = torch.tensor(graph[0], dtype=torch.float)\n",
    "    y = torch.tensor(graph[1] + 1, dtype=torch.long)\n",
    "    edge_indices = torch.tensor(list(permutations(np.arange(x.size(0)), r=2)), dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_indices, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[11, 3], edge_index=[2, 110], y=[11])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VRPDataset(Dataset):\n",
    "    def __init__(self, raw_data):\n",
    "        super(VRPDataset, self).__init__()\n",
    "        self.graph_data = self._process(raw_data)\n",
    "        \n",
    "    def _process(self, raw_data):\n",
    "        return [get_data(d) for d in raw_data]\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.graph_data)\n",
    "\n",
    "    def get(self, index):\n",
    "        return self.graph_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VRPDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(VRPDataset(2000), Data(x=[11, 3], edge_index=[2, 110], y=[11]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Build the actual baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "NODE_HIDDEN = 1\n",
    "EDGE_HIDDEN = 1\n",
    "GCN_NUM_LAYERS = 1\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.node_embedding = nn.Linear(dataset.num_features, NODE_HIDDEN)\n",
    "        self.edge_embedding = nn.Linear()\n",
    "        \n",
    "        self.conv1 = GATConv(dataset.num_features, hidden_channels)\n",
    "#         self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "#         x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "weight_decay = 0.96\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GATConv(3, 16, heads=1)\n",
       "  (fc): Linear(in_features=16, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.softmax(dim=1).argmax(dim=1)\n",
    "\n",
    "        test_correct = pred == data.y\n",
    "        test_acc = int(test_correct.sum()) / int(test_correct.size(0))\n",
    "    \n",
    "        return test_acc, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(VRPDataset(1600), VRPDataset(400))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = dataset[:int(len(dataset) * 0.8)]\n",
    "test_set = dataset[int(len(dataset) * 0.8):]\n",
    "\n",
    "training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 1.3348\n",
      "Epoch: 02, Loss: 1.3546\n",
      "Epoch: 03, Loss: 1.3897\n",
      "Epoch: 04, Loss: 1.4172\n",
      "Epoch: 05, Loss: 1.4337\n",
      "Epoch: 06, Loss: 1.4429\n",
      "Epoch: 07, Loss: 1.4477\n",
      "Epoch: 08, Loss: 1.4502\n",
      "Epoch: 09, Loss: 1.4517\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    epoch_loss = 0\n",
    "    for graph in training_set:\n",
    "        loss = train(graph)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36363636363636365, tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_set[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
