{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c22e3c3",
   "metadata": {},
   "source": [
    "## Paper: Efficiently solving the practical vehicle routing problem\n",
    "\n",
    "Source: `Duan et al., ‘Efficiently Solving the Practical Vehicle Routing Problem’.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed8492b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38bd6802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5583a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTANCE_PATH = Path(\"data\")\n",
    "RESULTS_PATH = Path(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57baedbb",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310d70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH / \"vrp_4_25.pkl\", 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    \n",
    "with open(INSTANCE_PATH / 'instances.pkl', 'rb') as f:\n",
    "    instances = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5dc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_dataset = [(x, y['routes']) for (x, y) in zip(instances, results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd5f18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_dataset = [(x, y['classifications']) for (x, y) in zip(instances, results)]\n",
    "graphs = graphs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f012187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.5       , 0.5       , 0.        ],\n",
       "        [0.06505159, 0.94888554, 2.        ],\n",
       "        [0.96563203, 0.80839735, 4.        ],\n",
       "        [0.30461377, 0.09767211, 8.        ],\n",
       "        [0.68423303, 0.44015249, 7.        ],\n",
       "        [0.12203823, 0.49517691, 9.        ],\n",
       "        [0.03438852, 0.9093204 , 8.        ],\n",
       "        [0.25877998, 0.66252228, 5.        ],\n",
       "        [0.31171108, 0.52006802, 2.        ],\n",
       "        [0.54671028, 0.18485446, 5.        ],\n",
       "        [0.96958463, 0.77513282, 8.        ]]),\n",
       " array([-1,  0,  1,  2,  1,  0,  0,  0,  2,  2,  1]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3161d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_matrix(num_nodes, routes):\n",
    "    adj_matrix = torch.zeros((num_nodes, num_nodes), dtype=torch.float32)\n",
    "\n",
    "    for path in routes.values():\n",
    "        if len(path) == 0:\n",
    "            continue\n",
    "\n",
    "        path = [0] + path + [0]\n",
    "\n",
    "        for i in range(0, len(path) - 1):\n",
    "            x_i = path[i]\n",
    "            x_j = path[i + 1]\n",
    "\n",
    "            adj_matrix[x_i][x_j] = adj_matrix[x_j][x_i] = 1\n",
    "\n",
    "    return adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4bbdb023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(pointA, pointB):\n",
    "    # Efficient way to calculate the euclidean distance\n",
    "    return np.linalg.norm(pointA - pointB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1508571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_graph(graph):\n",
    "    nodes, label = graph\n",
    "    \n",
    "    label = torch.tensor(label + 1, dtype=torch.int64)\n",
    "#     label = get_adj_matrix(nodes.shape[0], label)\n",
    "    graph = torch.tensor(nodes[:, :-1], dtype=torch.float32)\n",
    "    demand = torch.tensor(nodes[:, -1], dtype=torch.float32)\n",
    "    distance = np.zeros((nodes.shape[0], nodes.shape[0]))\n",
    "\n",
    "    for i in range(len(distance)):\n",
    "        for j in range(i + 1, len(distance)):\n",
    "            d = get_distance(graph[i], graph[j])\n",
    "            distance[i][j] = d\n",
    "            distance[j][i] = d\n",
    "            \n",
    "    distance = torch.tensor(distance, dtype=torch.float32)\n",
    "            \n",
    "    return graph, demand, distance, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ad751fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.graphs = []\n",
    "        self.demands = []\n",
    "        self.distances = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            processed = pre_process_graph(data[i])\n",
    "            \n",
    "            self.graphs.append(processed[0])\n",
    "            self.demands.append(processed[1])\n",
    "            self.distances.append(processed[2])\n",
    "            self.labels.append(processed[3])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]\n",
    "        demand = self.demands[idx]\n",
    "        distance = self.distances[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return graph, demand, distance, label\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"GraphDataset(graphs={len(self.graphs)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e503b7",
   "metadata": {},
   "source": [
    "The dataset should still be split in a train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "390f7d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GraphDataset(graphs=1900), GraphDataset(graphs=100))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_off = int(len(graphs) * 0.95)\n",
    "\n",
    "graph_train_dataset = GraphDataset(graphs_dataset[:cut_off])\n",
    "graph_test_dataset = GraphDataset(graphs_dataset[cut_off:])\n",
    "\n",
    "graph_train_dataset, graph_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a36435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(graph_train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(graph_test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c38e8d",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "Own MLP used for edge prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "241791fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer Perceptron for output prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, output_dim, L=2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.L = L\n",
    "        U = []\n",
    "        for layer in range(self.L - 1):\n",
    "            U.append(nn.Linear(hidden_dim, hidden_dim, True))\n",
    "        self.U = nn.ModuleList(U)\n",
    "        self.V = nn.Linear(hidden_dim, output_dim, True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input features (batch_size, hidden_dim)\n",
    "\n",
    "        Returns:\n",
    "            y: Output predictions (batch_size, output_dim)\n",
    "        \"\"\"\n",
    "        Ux = x\n",
    "        for U_i in self.U:\n",
    "            Ux = U_i(Ux)  # B x H\n",
    "            Ux = F.relu(Ux)  # B x H\n",
    "        y = self.V(Ux)  # B x O\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b5bf0",
   "metadata": {},
   "source": [
    "## Attention Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24f45587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(AttentionEncoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, neighbor):\n",
    "        '''\n",
    "        @param x: (batch_size, node_num, hidden_dim)\n",
    "        @param neighbor: (batch_size, node_num, k, hidden_dim)\n",
    "        '''\n",
    "        # scaled dot-product attention\n",
    "        x = x.unsqueeze(2)\n",
    "        neighbor = neighbor.permute(0, 1, 3, 2)\n",
    "        attn_score = F.softmax(torch.matmul(x, neighbor) / np.sqrt(self.hidden_dim), dim=-1) # (batch_size, node_num, 1, k)\n",
    "        weighted_neighbor = attn_score * neighbor\n",
    "        \n",
    "        # aggregation\n",
    "        agg = x.squeeze(2) + torch.sum(weighted_neighbor, dim=-1)\n",
    "        \n",
    "        return agg\n",
    "\n",
    "class AttentionPointer(nn.Module):\n",
    "    def __init__(self, hidden_dim, use_tanh=False, use_cuda=False):\n",
    "        super(AttentionPointer, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.use_tanh = use_tanh\n",
    "\n",
    "        self.project_hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.project_x = nn.Conv1d(hidden_dim, hidden_dim, 1, 1)\n",
    "        self.C = 10\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        v = torch.FloatTensor(hidden_dim)\n",
    "        if use_cuda:\n",
    "            v = v.cuda()\n",
    "        self.v = nn.Parameter(v)\n",
    "        self.v.data.uniform_(-(1. / math.sqrt(hidden_dim)) , 1. / math.sqrt(hidden_dim))\n",
    "\n",
    "    def forward(self, hidden, x):\n",
    "        '''\n",
    "        @param hidden: (batch_size, hidden_dim)\n",
    "        @param x: (node_num, batch_size, hidden_dim)\n",
    "        '''\n",
    "        x = x.permute(1, 2, 0)\n",
    "        q = self.project_hidden(hidden).unsqueeze(2)  # batch_size x hidden_dim x 1\n",
    "        e = self.project_x(x)  # batch_size x hidden_dim x node_num \n",
    "        # expand the hidden by node_num\n",
    "        # batch_size x hidden_dim x node_num\n",
    "        expanded_q = q.repeat(1, 1, e.size(2)) \n",
    "        # batch x 1 x hidden_dim\n",
    "        v_view = self.v.unsqueeze(0).expand(expanded_q.size(0), len(self.v)).unsqueeze(1)\n",
    "        # (batch_size x 1 x hidden_dim) * (batch_size x hidden_dim x node_num)\n",
    "        u = torch.bmm(v_view, self.tanh(expanded_q + e)).squeeze(1)\n",
    "        if self.use_tanh:\n",
    "            logits = self.C * self.tanh(u)\n",
    "        else:\n",
    "            logits = u  \n",
    "        return e, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e4fa8",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2236694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 node_hidden_dim,\n",
    "                 edge_hidden_dim,\n",
    "                 gcn_num_layers,\n",
    "                 k):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.node_hidden_dim = node_hidden_dim\n",
    "        self.edge_hidden_dim = edge_hidden_dim\n",
    "        self.gcn_num_layers = gcn_num_layers\n",
    "        self.k = k\n",
    "        \n",
    "        self.W1 = nn.Linear(2, self.node_hidden_dim)      # node_W1\n",
    "        self.W2 = nn.Linear(2, self.node_hidden_dim // 2) # node_W2\n",
    "        self.W3 = nn.Linear(1, self.node_hidden_dim // 2) # node_W3\n",
    "        self.W4 = nn.Linear(1, self.edge_hidden_dim // 2) # edge_W4\n",
    "        self.W5 = nn.Linear(1, self.edge_hidden_dim // 2) # edge_W5\n",
    "        \n",
    "        self.node_embedding = nn.Linear(self.node_hidden_dim, self.node_hidden_dim, bias=False) # Eq5\n",
    "        self.edge_embedding = nn.Linear(self.edge_hidden_dim, self.edge_hidden_dim, bias=False) # Eq6\n",
    "\n",
    "        self.gcn_layers = nn.ModuleList([GCNLayer(self.node_hidden_dim) for i in range(self.gcn_num_layers)])\n",
    "        \n",
    "        # Concat of the data (OWN)\n",
    "        num_classes = 5\n",
    "        self.mlp = MLP(hidden_dim=self.node_hidden_dim, L=2, output_dim=num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def adjacency(self, m):\n",
    "        '''\n",
    "        @param m: distance (node_num, node_num)\n",
    "        '''\n",
    "        a = torch.zeros_like(m)\n",
    "        idx = torch.argsort(m, dim=1)[:, 1:(self.k+1)]\n",
    "        a.scatter_(1, idx, 1)\n",
    "        a.fill_diagonal_(-1)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def find_neighbors(self, m):\n",
    "        ''' find index of neighbors for each node\n",
    "        @param m: distance (batch_size, node_num, node_num)\n",
    "        '''\n",
    "        neighbor_idx = []\n",
    "        for i in range(m.shape[0]):\n",
    "            idx = torch.argsort(m[i, :, :], dim=1)[:, 1:(self.k+1)].numpy()\n",
    "            neighbor_idx.append(idx)\n",
    "        return torch.LongTensor(neighbor_idx).to(device)\n",
    "\n",
    "    def forward(self, x_c, x_d, m):\n",
    "        '''\n",
    "        @param x_c: coordination (batch_size, node_num(N+1), 2)\n",
    "        @param x_d: demand (batch_size, node_num(N+1))\n",
    "        @param m: distance (batch_size, node_num(N+1), node_num(N+1))\n",
    "        '''\n",
    "        # Eq 2\n",
    "        x0 = self.relu(self.W1(x_c[:, :1, :])) # (batch_size, 1, node_hidden_dim)\n",
    "        xi = self.relu(torch.cat((self.W2(x_c[:, 1:, :]), self.W3(x_d.unsqueeze(2)[:, 1:, :])), dim=-1)) # (batch_size, node_num(N), node_hidden_dim)\n",
    "        x = torch.cat((x0, xi), dim=1)\n",
    "        # Eq 3\n",
    "        a = torch.Tensor([self.adjacency(m[i, :, :]).numpy() for i in range(m.shape[0])]).to(device)\n",
    "        # Eq 4\n",
    "        y = self.relu(torch.cat((self.W4(m.unsqueeze(3)), self.W5(a.unsqueeze(3))), dim=-1))\n",
    "        # Eq 5\n",
    "        h_node = self.node_embedding(x)\n",
    "        # Eq 6\n",
    "        h_edge = self.edge_embedding(y)\n",
    "\n",
    "        # index of neighbors\n",
    "        N = self.find_neighbors(m)\n",
    "\n",
    "        # GCN layers\n",
    "        for gcn_layer in self.gcn_layers:\n",
    "            h_node, h_edge = gcn_layer(h_node, h_edge, N)\n",
    "            \n",
    "        # Merge together (OWN)\n",
    "#         print(h_node.shape, h_edge.shape)\n",
    "        f = self.mlp(h_node)\n",
    "    \n",
    "#         return h_node, h_edge\n",
    "        return f\n",
    "\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(GCNLayer, self).__init__()\n",
    "\n",
    "        # node GCN layers\n",
    "        self.W_node = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V_node_in = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V_node = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.attn = AttentionEncoder(hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln1_node = nn.LayerNorm(hidden_dim)\n",
    "        self.ln2_node = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # edge GCN layers\n",
    "        self.W_edge = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V_edge_in = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V_edge = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.W1_edge = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W2_edge = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W3_edge = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln1_edge = nn.LayerNorm(hidden_dim)\n",
    "        self.ln2_edge = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, e, neighbor_index):\n",
    "        '''\n",
    "        @param x: (batch_size, node_num(N+1), node_hidden_dim)\n",
    "        @param e: (batch_size, node_num(N+1), node_num(N+1), edge_hidden_dim)\n",
    "        @param neighbor_index: (batch_size, node_num(N+1), k)\n",
    "        '''\n",
    "        # node embedding\n",
    "        batch_size, node_num = x.size(0), x.size(1)\n",
    "        node_hidden_dim = x.size(-1)\n",
    "        t = x.unsqueeze(1).repeat(1, node_num, 1, 1)\n",
    "\n",
    "        neighbor_index = neighbor_index.unsqueeze(3).repeat(1, 1, 1, node_hidden_dim)\n",
    "        neighbor = t.gather(2, neighbor_index)\n",
    "        neighbor = neighbor.view(batch_size, node_num, -1, node_hidden_dim)\n",
    "        \n",
    "        # Eq 7/9\n",
    "        h_nb_node = self.ln1_node(x + self.relu(self.W_node(self.attn(x, neighbor))))\n",
    "        # Eq 12, Eq 8\n",
    "        h_node = self.ln2_node(h_nb_node + self.relu(self.V_node(torch.cat([self.V_node_in(x), h_nb_node], dim=-1))))\n",
    "\n",
    "        # edge embedding\n",
    "        x_from = x.unsqueeze(2).repeat(1, 1, node_num, 1)\n",
    "        x_to = x.unsqueeze(1).repeat(1, node_num, 1, 1)\n",
    "        # Eq 7/10, Eq 11\n",
    "        h_nb_edge = self.ln1_edge(e + self.relu(self.W_edge(self.W1_edge(e) + self.W2_edge(x_from) + self.W3_edge(x_to))))\n",
    "        # Eq 13, Eq 8\n",
    "        h_edge = self.ln2_edge(h_nb_edge + self.relu(self.V_edge(torch.cat((self.V_edge_in(e), h_nb_edge), dim=-1))))\n",
    "\n",
    "        return h_node, h_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3073a294",
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_HIDDEN_DIM = 100\n",
    "EDGE_HIDDEN_DIM = 100\n",
    "GCN_LAYER = 1\n",
    "k = 1\n",
    "\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1.01\n",
    "\n",
    "model = GCN(node_hidden_dim=NODE_HIDDEN_DIM,\n",
    "            edge_hidden_dim=EDGE_HIDDEN_DIM,\n",
    "            gcn_num_layers=GCN_LAYER,\n",
    "            k=k).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=learning_rate,\n",
    "                             weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4f27773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (W1): Linear(in_features=2, out_features=100, bias=True)\n",
       "  (W2): Linear(in_features=2, out_features=50, bias=True)\n",
       "  (W3): Linear(in_features=1, out_features=50, bias=True)\n",
       "  (W4): Linear(in_features=1, out_features=50, bias=True)\n",
       "  (W5): Linear(in_features=1, out_features=50, bias=True)\n",
       "  (node_embedding): Linear(in_features=100, out_features=100, bias=False)\n",
       "  (edge_embedding): Linear(in_features=100, out_features=100, bias=False)\n",
       "  (gcn_layers): ModuleList(\n",
       "    (0): GCNLayer(\n",
       "      (W_node): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (V_node_in): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (V_node): Linear(in_features=200, out_features=100, bias=True)\n",
       "      (attn): AttentionEncoder()\n",
       "      (relu): ReLU()\n",
       "      (ln1_node): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2_node): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (W_edge): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (V_edge_in): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (V_edge): Linear(in_features=200, out_features=100, bias=True)\n",
       "      (W1_edge): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (W2_edge): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (W3_edge): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (ln1_edge): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2_edge): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (U): ModuleList(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "    (V): Linear(in_features=100, out_features=5, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30777a5",
   "metadata": {},
   "source": [
    "## Node classification prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "608eb976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    out = out.numpy()\n",
    "    labels = labels.numpy()\n",
    "    \n",
    "    acc = np.sum(out == labels, axis=1) / out.shape[1]\n",
    "    \n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e2ef678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_c, x_d, m, y):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(x_c, x_d, m)\n",
    "        out = out.reshape(out.size(0), 5, -1)\n",
    "        out = out.softmax(1)\n",
    "        out = out.argmax(1)\n",
    "\n",
    "        return accuracy(out, y), out\n",
    "    \n",
    "def train_one_epoch(x_c, x_d, m, y):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(x_c, x_d, m)\n",
    "    out = out.permute(0, 2, 1)\n",
    "    \n",
    "    loss = criterion(out, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train(num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "    \n",
    "        for x_c, x_d, m, y in train_dataloader:\n",
    "            x_c, x_d, m, y = x_c.to(device), x_d.to(device), m.to(device), y.to(device)\n",
    "\n",
    "            loss = train_one_epoch(x_c, x_d, m, y)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e03d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Loss: 1.4454\n",
      "Epoch: 01, Loss: 1.4333\n",
      "Epoch: 02, Loss: 1.4162\n",
      "Epoch: 03, Loss: 1.3676\n",
      "Epoch: 04, Loss: 1.4035\n",
      "Epoch: 05, Loss: 1.3799\n",
      "Epoch: 06, Loss: 1.3267\n",
      "Epoch: 07, Loss: 1.3401\n",
      "Epoch: 08, Loss: 1.3741\n",
      "Epoch: 09, Loss: 1.3038\n"
     ]
    }
   ],
   "source": [
    "train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "edd2b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c, x_d, m, y = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2fbf3784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18181818181818182,\n",
       " tensor([[1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 0, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 2],\n",
       "         [2, 1, 4, 3, 3, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 3, 2, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 4, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 4, 2, 1, 0, 4, 4, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 0, 4, 3, 1],\n",
       "         [2, 1, 4, 4, 3, 2, 0, 4, 4, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 2, 0, 4, 4, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 1, 4, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 3, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 0, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 2, 1, 1, 4, 3, 3, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 1, 4, 3, 3, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 3, 1],\n",
       "         [1, 1, 4, 4, 3, 1, 1, 4, 3, 3, 1],\n",
       "         [2, 1, 4, 3, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 4, 2, 2],\n",
       "         [1, 1, 4, 4, 3, 1, 0, 0, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 2, 2, 0, 0, 4, 2, 2],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 3, 1, 0, 0, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 4, 2, 1, 1, 4, 4, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [2, 1, 4, 4, 2, 1, 0, 4, 4, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 4, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 2, 0, 4, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 3, 2, 0, 4, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 3, 1],\n",
       "         [2, 1, 4, 4, 2, 1, 0, 4, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 2, 1, 1, 4, 4, 3, 1],\n",
       "         [1, 1, 4, 3, 3, 1, 1, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 3, 2, 1, 4, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 2, 2, 1, 4, 3, 2, 2],\n",
       "         [2, 1, 4, 4, 2, 1, 0, 0, 4, 3, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 2, 1, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 4, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 0, 3, 3, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 4, 2, 1, 1, 4, 3, 3, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 3, 3, 1],\n",
       "         [2, 1, 4, 3, 2, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 2, 0, 4, 3, 3, 1],\n",
       "         [1, 1, 4, 4, 2, 1, 0, 4, 4, 3, 1],\n",
       "         [2, 1, 4, 3, 2, 2, 0, 4, 4, 2, 1],\n",
       "         [1, 1, 4, 4, 2, 1, 1, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 2, 0, 4, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 2, 2, 0, 4, 3, 3, 1],\n",
       "         [1, 1, 4, 4, 2, 2, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 3, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 1, 4, 3, 2, 2],\n",
       "         [1, 1, 4, 3, 3, 1, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 2, 0, 4, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 0, 3, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 4, 4, 2, 1],\n",
       "         [1, 1, 4, 3, 2, 1, 0, 0, 3, 2, 1]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(x_c, x_d, m, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad72ed4",
   "metadata": {},
   "source": [
    "## Edge probability prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a9ff71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "93f2eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_c, x_d, m, y):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(x_c, x_d, m)\n",
    "        out = out.log_softmax(dim=3)\n",
    "        out = out.permute(0, 3, 1, 2)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "def train_one_epoch(x_c, x_d, m, y):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(x_c, x_d, m)\n",
    "    out = F.log_softmax(out, dim=3)\n",
    "    out = out.permute(0, 3, 1, 2).contiguous()\n",
    "    \n",
    "    loss = criterion()(out, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train(num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "    \n",
    "        for x_c, x_d, m, y in train_dataloader:\n",
    "            x_c, x_d, m, y = x_c.to(device), x_d.to(device), m.to(device), y.to(device).to(torch.long)\n",
    "\n",
    "            loss = train_one_epoch(x_c, x_d, m, y)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9e7f4c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Loss: 0.5906\n",
      "Epoch: 01, Loss: 0.5840\n",
      "Epoch: 02, Loss: 0.5787\n",
      "Epoch: 03, Loss: 0.5745\n",
      "Epoch: 04, Loss: 0.5721\n"
     ]
    }
   ],
   "source": [
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "57d59a47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph, demand, distance, label = next(iter(train_dataloader))\n",
    "\n",
    "out = test(graph, demand, distance, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3c6fdb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 11, 11])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "969b080f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6732fc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
