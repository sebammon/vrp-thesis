{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a979532",
   "metadata": {},
   "source": [
    "## Paper: Efficiently solving the practical vehicle routing problem\n",
    "\n",
    "Source: `Duan et al., ‘Efficiently Solving the Practical Vehicle Routing Problem’.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8e3bad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e28a39fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3999f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTANCE_PATH = Path(\"data\")\n",
    "RESULTS_PATH = Path(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9e418b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INSTANCE_PATH / 'dataset.pkl', 'rb') as f:\n",
    "    graphs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d79a0bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.5       , 0.5       , 0.        ],\n",
       "        [0.06505159, 0.94888554, 2.        ],\n",
       "        [0.96563203, 0.80839735, 4.        ],\n",
       "        [0.30461377, 0.09767211, 8.        ],\n",
       "        [0.68423303, 0.44015249, 7.        ],\n",
       "        [0.12203823, 0.49517691, 9.        ],\n",
       "        [0.03438852, 0.9093204 , 8.        ],\n",
       "        [0.25877998, 0.66252228, 5.        ],\n",
       "        [0.31171108, 0.52006802, 2.        ],\n",
       "        [0.54671028, 0.18485446, 5.        ],\n",
       "        [0.96958463, 0.77513282, 8.        ]]),\n",
       " array([-1,  0,  1,  2,  1,  0,  0,  0,  2,  2,  1]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e630e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(pointA, pointB):\n",
    "    # Efficient way to calculate the euclidean distance\n",
    "    return np.linalg.norm(pointA - pointB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6b257825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_graph(graph):\n",
    "    nodes, label = graph\n",
    "    \n",
    "    label = torch.tensor(label + 1, dtype=torch.int64)\n",
    "    graph = torch.tensor(nodes[:, :-1], dtype=torch.float32)\n",
    "    demand = torch.tensor(nodes[:, -1], dtype=torch.float32)\n",
    "    distance = np.zeros((nodes.shape[0], nodes.shape[0]))\n",
    "\n",
    "    for i in range(len(distance)):\n",
    "        for j in range(i + 1, len(distance)):\n",
    "            d = get_distance(graph[i], graph[j])\n",
    "            distance[i][j] = d\n",
    "            distance[j][i] = d\n",
    "            \n",
    "    distance = torch.tensor(distance, dtype=torch.float32)\n",
    "            \n",
    "    return graph, demand, distance, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4db7f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.graphs = []\n",
    "        self.demands = []\n",
    "        self.distances = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            processed = pre_process_graph(data[i])\n",
    "            \n",
    "            self.graphs.append(processed[0])\n",
    "            self.demands.append(processed[1])\n",
    "            self.distances.append(processed[2])\n",
    "            self.labels.append(processed[3])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]\n",
    "        demand = self.demands[idx]\n",
    "        distance = self.distances[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return graph, demand, distance, label\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"GraphDataset(graphs={len(self.graphs)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e802f48",
   "metadata": {},
   "source": [
    "The dataset should still be split in a train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a75d2e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphDataset(graphs=2000)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_dataset = GraphDataset(graphs)\n",
    "graph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d3655111",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(graph_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767bd3f",
   "metadata": {},
   "source": [
    "## Attention Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "00581dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(AttentionEncoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, neighbor):\n",
    "        '''\n",
    "        @param x: (batch_size, node_num, hidden_dim)\n",
    "        @param neighbor: (batch_size, node_num, k, hidden_dim)\n",
    "        '''\n",
    "        # scaled dot-product attention\n",
    "        x = x.unsqueeze(2)\n",
    "        neighbor = neighbor.permute(0, 1, 3, 2)\n",
    "        attn_score = F.softmax(torch.matmul(x, neighbor) / np.sqrt(self.hidden_dim), dim=-1) # (batch_size, node_num, 1, k)\n",
    "        weighted_neighbor = attn_score * neighbor\n",
    "        \n",
    "        # aggregation\n",
    "        agg = x.squeeze(2) + torch.sum(weighted_neighbor, dim=-1)\n",
    "        \n",
    "        return agg\n",
    "\n",
    "class AttentionPointer(nn.Module):\n",
    "    def __init__(self, hidden_dim, use_tanh=False, use_cuda=False):\n",
    "        super(AttentionPointer, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.use_tanh = use_tanh\n",
    "\n",
    "        self.project_hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.project_x = nn.Conv1d(hidden_dim, hidden_dim, 1, 1)\n",
    "        self.C = 10\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        v = torch.FloatTensor(hidden_dim)\n",
    "        if use_cuda:\n",
    "            v = v.cuda()\n",
    "        self.v = nn.Parameter(v)\n",
    "        self.v.data.uniform_(-(1. / math.sqrt(hidden_dim)) , 1. / math.sqrt(hidden_dim))\n",
    "\n",
    "    def forward(self, hidden, x):\n",
    "        '''\n",
    "        @param hidden: (batch_size, hidden_dim)\n",
    "        @param x: (node_num, batch_size, hidden_dim)\n",
    "        '''\n",
    "        x = x.permute(1, 2, 0)\n",
    "        q = self.project_hidden(hidden).unsqueeze(2)  # batch_size x hidden_dim x 1\n",
    "        e = self.project_x(x)  # batch_size x hidden_dim x node_num \n",
    "        # expand the hidden by node_num\n",
    "        # batch_size x hidden_dim x node_num\n",
    "        expanded_q = q.repeat(1, 1, e.size(2)) \n",
    "        # batch x 1 x hidden_dim\n",
    "        v_view = self.v.unsqueeze(0).expand(expanded_q.size(0), len(self.v)).unsqueeze(1)\n",
    "        # (batch_size x 1 x hidden_dim) * (batch_size x hidden_dim x node_num)\n",
    "        u = torch.bmm(v_view, self.tanh(expanded_q + e)).squeeze(1)\n",
    "        if self.use_tanh:\n",
    "            logits = self.C * self.tanh(u)\n",
    "        else:\n",
    "            logits = u  \n",
    "        return e, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78128436",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ddd4c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 node_hidden_dim,\n",
    "                 edge_hidden_dim,\n",
    "                 gcn_num_layers,\n",
    "                 k):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.node_hidden_dim = node_hidden_dim\n",
    "        self.edge_hidden_dim = edge_hidden_dim\n",
    "        self.gcn_num_layers = gcn_num_layers\n",
    "        self.k = k\n",
    "        \n",
    "        self.W1 = nn.Linear(2, self.node_hidden_dim)      # node_W1\n",
    "        self.W2 = nn.Linear(2, self.node_hidden_dim // 2) # node_W2\n",
    "        self.W3 = nn.Linear(1, self.node_hidden_dim // 2) # node_W3\n",
    "        self.W4 = nn.Linear(1, self.edge_hidden_dim // 2) # edge_W4\n",
    "        self.W5 = nn.Linear(1, self.edge_hidden_dim // 2) # edge_W5\n",
    "        \n",
    "        self.node_embedding = nn.Linear(self.node_hidden_dim, self.node_hidden_dim, bias=False) # Eq5\n",
    "        self.edge_embedding = nn.Linear(self.edge_hidden_dim, self.edge_hidden_dim, bias=False) # Eq6\n",
    "\n",
    "        self.gcn_layers = nn.ModuleList([GCNLayer(self.node_hidden_dim) for i in range(self.gcn_num_layers)])\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def adjacency(self, m):\n",
    "        '''\n",
    "        @param m: distance (node_num, node_num)\n",
    "        '''\n",
    "        a = torch.zeros_like(m)\n",
    "        idx = torch.argsort(m, dim=1)[:, 1:(self.k+1)]\n",
    "        a.scatter_(1, idx, 1)\n",
    "        a.fill_diagonal_(-1)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def find_neighbors(self, m):\n",
    "        ''' find index of neighbors for each node\n",
    "        @param m: distance (batch_size, node_num, node_num)\n",
    "        '''\n",
    "        neighbor_idx = []\n",
    "        for i in range(m.shape[0]):\n",
    "            idx = torch.argsort(m[i, :, :], dim=1)[:, 1:(self.k+1)].numpy()\n",
    "            neighbor_idx.append(idx)\n",
    "        return torch.LongTensor(neighbor_idx).to(device)\n",
    "\n",
    "    def forward(self, x_c, x_d, m):\n",
    "        '''\n",
    "        @param x_c: coordination (batch_size, node_num(N+1), 2)\n",
    "        @param x_d: demand (batch_size, node_num(N+1))\n",
    "        @param m: distance (batch_size, node_num(N+1), node_num(N+1))\n",
    "        '''\n",
    "        # Eq 2\n",
    "        x0 = self.relu(self.W1(x_c[:, :1, :])) # (batch_size, 1, node_hidden_dim)\n",
    "        xi = self.relu(torch.cat((self.W2(x_c[:, 1:, :]), self.W3(x_d.unsqueeze(2)[:, 1:, :])), dim=-1)) # (batch_size, node_num(N), node_hidden_dim)\n",
    "        x = torch.cat((x0, xi), dim=1)\n",
    "        # Eq 3\n",
    "        a = torch.Tensor([self.adjacency(m[i, :, :]).numpy() for i in range(m.shape[0])]).to(device)\n",
    "        # Eq 4\n",
    "        y = self.relu(torch.cat((self.W4(m.unsqueeze(3)), self.W5(a.unsqueeze(3))), dim=-1))\n",
    "        # Eq 5\n",
    "        h_node = self.node_embedding(x)\n",
    "        # Eq 6\n",
    "        h_edge = self.edge_embedding(y)\n",
    "\n",
    "        # index of neighbors\n",
    "        N = self.find_neighbors(m)\n",
    "\n",
    "        # GCN layers\n",
    "        for gcn_layer in self.gcn_layers:\n",
    "            h_node, h_edge = gcn_layer(h_node, h_edge, N)\n",
    "\n",
    "        return h_node, h_edge\n",
    "\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(GCNLayer, self).__init__()\n",
    "\n",
    "        # node GCN layers\n",
    "        self.W_node = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V_node_in = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V_node = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.attn = AttentionEncoder(hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln1_node = nn.LayerNorm(hidden_dim)\n",
    "        self.ln2_node = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # edge GCN layers\n",
    "        self.W_edge = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V_edge_in = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V_edge = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.W1_edge = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W2_edge = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W3_edge = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln1_edge = nn.LayerNorm(hidden_dim)\n",
    "        self.ln2_edge = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, e, neighbor_index):\n",
    "        '''\n",
    "        @param x: (batch_size, node_num(N+1), node_hidden_dim)\n",
    "        @param e: (batch_size, node_num(N+1), node_num(N+1), edge_hidden_dim)\n",
    "        @param neighbor_index: (batch_size, node_num(N+1), k)\n",
    "        '''\n",
    "        # node embedding\n",
    "        batch_size, node_num = x.size(0), x.size(1)\n",
    "        node_hidden_dim = x.size(-1)\n",
    "        t = x.unsqueeze(1).repeat(1, node_num, 1, 1)\n",
    "\n",
    "        neighbor_index = neighbor_index.unsqueeze(3).repeat(1, 1, 1, node_hidden_dim)\n",
    "        neighbor = t.gather(2, neighbor_index)\n",
    "        neighbor = neighbor.view(batch_size, node_num, -1, node_hidden_dim)\n",
    "        \n",
    "        # Eq 7/9\n",
    "        h_nb_node = self.ln1_node(x + self.relu(self.W_node(self.attn(x, neighbor))))\n",
    "        # Eq 12, Eq 8\n",
    "        h_node = self.ln2_node(h_nb_node + self.relu(self.V_node(torch.cat([self.V_node_in(x), h_nb_node], dim=-1))))\n",
    "\n",
    "        # edge embedding\n",
    "        x_from = x.unsqueeze(2).repeat(1, 1, node_num, 1)\n",
    "        x_to = x.unsqueeze(1).repeat(1, node_num, 1, 1)\n",
    "        # Eq 7/10, Eq 11\n",
    "        h_nb_edge = self.ln1_edge(e + self.relu(self.W_edge(self.W1_edge(e) + self.W2_edge(x_from) + self.W3_edge(x_to))))\n",
    "        # Eq 13, Eq 8\n",
    "        h_edge = self.ln2_edge(h_nb_edge + self.relu(self.V_edge(torch.cat((self.V_edge_in(e), h_nb_edge), dim=-1))))\n",
    "\n",
    "        return h_node, h_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ea4a9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_HIDDEN = 2\n",
    "EDGE_HIDDEN = 2\n",
    "GCN_LAYER = 2\n",
    "k = 1\n",
    "\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0.96\n",
    "\n",
    "model = GCN(node_hidden_dim=NODE_HIDDEN,\n",
    "            edge_hidden_dim=EDGE_HIDDEN,\n",
    "            gcn_num_layers=GCN_LAYER,\n",
    "            k=k).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=learning_rate,\n",
    "                             weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "eeb5659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c, x_d, m, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "13a15033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 11, 2]), torch.Size([64, 11]), torch.Size([64, 11, 11]))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_c.shape, x_d.shape, m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "da7222b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_c, x_d, m = x_c.to(device), x_d.to(device), m.to(device)\n",
    "    h_node, h_edge = model(x_c, x_d, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b998845f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 11, 2]), torch.Size([64, 11, 11, 2]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_node.shape, h_edge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc16ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
